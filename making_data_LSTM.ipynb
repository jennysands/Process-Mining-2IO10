{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown extension: http://www.xes-standard.org/meta_3TU.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_org.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_time.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_general.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_life.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_concept.xesext\n",
      "Parsing of the file Started...................\n",
      "\n",
      "Took -90.33 seconds for Parsing XES file......................\n",
      "\n",
      "..............................................\n",
      "Sample Parsed Data..............................\n",
      "(1202267, 21)\n",
      "1202262    1350494635\n",
      "1202263    1350494635\n",
      "1202264    1350494635\n",
      "1202265    1350494635\n",
      "1202266    1350494635\n",
      "Name: Id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as et\n",
    "import pandas as pd\n",
    "import time\n",
    " \n",
    "# Parser classes from openxes package\n",
    "from opyenxes.data_in.XUniversalParser import XUniversalParser\n",
    "from opyenxes.model.XEvent import XEvent\n",
    "from opyenxes.model.XTrace import XTrace\n",
    "from opyenxes.model.XAttributeBoolean import XAttributeBoolean\n",
    "from opyenxes.model.XAttributeCollection import XAttributeCollection\n",
    "from opyenxes.model.XAttributeContainer import XAttributeContainer\n",
    "from opyenxes.model.XAttributeContinuous import XAttributeContinuous\n",
    "from opyenxes.model.XAttributeDiscrete import XAttributeDiscrete\n",
    "from opyenxes.model.XAttributeID import XAttributeID\n",
    "from opyenxes.model.XAttributeList import XAttributeList\n",
    "from opyenxes.model.XAttributeLiteral import XAttributeLiteral\n",
    "from opyenxes.model.XAttributeMap import XAttributeMap\n",
    "from opyenxes.model.XAttributeTimestamp import XAttributeTimestamp\n",
    "\n",
    "log_fp = 'BPI Challenge 2017.xes.gz'\n",
    "\n",
    "with open(log_fp) as log_file:\n",
    "    log = XUniversalParser().parse(log_file)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class XLog2df:\n",
    "    def __init__(self):\n",
    "        self.__event_ind = 0\n",
    "        self.__trace_ind = 0\n",
    "        self.__event_df_dict = dict()\n",
    "        self.__trace_df_dict = dict()\n",
    "        \n",
    "    def parse_xattribute(self, xattrib):\n",
    "        is_list = isinstance(xattrib, XAttributeList)\n",
    "        is_container = isinstance(xattrib, XAttributeContainer)\n",
    "\n",
    "        if is_list or is_container:\n",
    "            return None, None, None\n",
    "        else:\n",
    "            return xattrib.get_key(), xattrib.get_value(), xattrib.get_extension()\n",
    "\n",
    "    def parse_xattribute_dict(self, xattribs):\n",
    "        return {key: self.parse_xattribute(val)[1] for key, val in xattribs.items()}\n",
    "\n",
    "    def xevents2df(self, events, caseid):\n",
    "        event_df_dict = dict()\n",
    "\n",
    "        for event in events:\n",
    "            assert isinstance(event, XEvent)\n",
    "            attrib_dict = self.parse_xattribute_dict(event.get_attributes())\n",
    "\n",
    "            # add caseid\n",
    "            CASEID = 'caseid'\n",
    "            attrib_dict[CASEID] = caseid\n",
    "            event_df_dict[self.__event_ind] = attrib_dict\n",
    "            self.__event_ind += 1\n",
    "            \n",
    "        return event_df_dict\n",
    "    \n",
    "    def xtraces2df(self, traces):\n",
    "        trace_df_dict = dict()\n",
    "        \n",
    "        for trace in traces:\n",
    "            attrib_dict = dict(trace.get_attributes())\n",
    "            attrib_dict = self.parse_xattribute_dict(attrib_dict)\n",
    "            trace_df_dict[self.__trace_ind] = attrib_dict\n",
    "            self.__trace_ind += 1\n",
    "            \n",
    "        return trace_df_dict\n",
    "    \n",
    "    def xlog2df(self, xlog):\n",
    "\n",
    "        print(\"Parsing of the file Started...................\\n\")\n",
    "        start = time.time()\n",
    "\n",
    "        trace_df_dict = self.xtraces2df(xlog)\n",
    "        event_df_dict = dict()\n",
    "        \n",
    "        for trace in xlog:\n",
    "            caseid = trace.get_attributes()['concept:name'].get_value()\n",
    "            event_df_dict_i = self.xevents2df(trace, caseid)\n",
    "            event_df_dict.update(event_df_dict_i)\n",
    "            \n",
    "        trace_df = pd.DataFrame.from_dict(trace_df_dict, 'index')\n",
    "        event_df = pd.DataFrame.from_dict(event_df_dict, 'index')\n",
    "        \n",
    "        # prefix trace attributes with \"trace:\" and event attributes with \"event:\"\n",
    "        trace_df.columns = ['trace:{}'.format(val) for val in trace_df.columns]\n",
    "        event_df_columns = []\n",
    "        CASEID = 'caseid'\n",
    "        \n",
    "        for val in event_df.columns:\n",
    "            renamed = 'event:{}'.format(val)\n",
    "            if val != CASEID:\n",
    "                event_df_columns.append(renamed)\n",
    "            else:\n",
    "                event_df_columns.append(val)\n",
    "        \n",
    "        event_df.columns = event_df_columns\n",
    "        \n",
    "        # merge trace_df and event_df on caseid\n",
    "        trace_df[CASEID] = trace_df['trace:concept:name']\n",
    "        \n",
    "        # key column needs to be string type\n",
    "        trace_df[CASEID] = trace_df[CASEID].astype(str)\n",
    "        event_df[CASEID] = event_df[CASEID].astype(str)\n",
    "\n",
    "        merged_df = pd.merge(trace_df, event_df, on=CASEID)\n",
    "\n",
    "        merged_df['event:org:resource'] = merged_df['event:org:resource'].astype(str)\n",
    "        merged_df['caseid'] = merged_df['caseid'].astype(str)\n",
    "        merged_df['trace:concept:name'] = merged_df['trace:concept:name'].astype(str)\n",
    "\n",
    "        merged_df[\"Id\"] = merged_df[\"caseid\"].apply(lambda x: x.split(\"_\")[1])\n",
    "\n",
    "        print(\"Took %.2f seconds for Parsing XES file......................\"%(start - time.time()))\n",
    "        print(\"\\n..............................................\")\n",
    "        print(\"Sample Parsed Data..............................\")\n",
    "        print(merged_df.shape)\n",
    "\n",
    "        return merged_df\n",
    "\n",
    "converter = XLog2df()\n",
    "\n",
    "event_row_df = converter.xlog2df(log)\n",
    "\n",
    "print(event_row_df.Id.tail())\n",
    "event_row_df.to_csv(\"log_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
